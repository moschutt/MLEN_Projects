{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Documentation page: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "> `class sklearn.linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)[source]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " slope:        3.33066907388e-16\n",
      "coefficient:  [ 1.]\n",
      "r^2 score:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe671022290>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe671271750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Required to get in-line images\n",
    "%matplotlib inline         \n",
    "\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the linear model library\n",
    "from sklearn import linear_model\n",
    "\n",
    "# create data\n",
    "X = [[0], [1], [2]]\n",
    "y = [0, 1, 2]\n",
    "\n",
    "# Create the object\n",
    "glm = linear_model.LinearRegression()\n",
    "\n",
    "# Fit model to data\n",
    "glm.fit(X, y)\n",
    "\n",
    "# Pring the coefficient(s)\n",
    "print 'slope:       ', glm.intercept_\n",
    "print 'coefficient: ', glm.coef_\n",
    "\n",
    "print 'r^2 score: ', glm.score(X, y)       # should be done against the test data but....\n",
    "\n",
    "# Create plot object\n",
    "# Print X and y as scatter plot\n",
    "# Print the predicted points as a line\n",
    "plt.clf()\n",
    "plt.scatter(X, y, color='b')\n",
    "plt.plot(X, glm.predict(X), color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (Classificaiton)\n",
    "\n",
    "Documentation page for decsion trees: http://scikit-learn.org/stable/modules/tree.html\n",
    "Documentation for DecisionTreeClassifier class : http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "\n",
    "> class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_split=1e-07, class_weight=None, presort=False)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <class 'sklearn.datasets.base.Bunch'>\n",
      "['target_names', 'data', 'target', 'DESCR', 'feature_names']\n",
      "<type 'numpy.ndarray'>\n",
      "[[ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]]\n",
      "<type 'numpy.ndarray'>\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "print type(iris)\n",
    "print iris.keys()\n",
    "print type(iris.data)\n",
    "print iris.data[1:10]\n",
    "print type(iris.target)\n",
    "print iris.target[1:10]\n",
    "\n",
    "# Create instance of classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "# fit the data to the classifier - Note that it returns a new clf because -- Um shit?\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "print clf\n",
    "\n",
    "print 'Accuracy = ', clf.score(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some parameters\n",
    "\n",
    "#### min_samples_split \n",
    "Minimum sampes requird to keep splitting.\n",
    "\n",
    "The smaller this value the more likely to over-fit.  The tree can go much deeper.\n",
    "\n",
    "#### criterion\n",
    "Select the information gain calculation.  Default is \"Gini\", but can be set to \"entropy\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "\n",
    "Is easy to calculate in R, and a bitch in python.  Why, python?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[ 1 -1]\n",
      "-1\n",
      "[1 2]\n",
      "[-1  1]\n",
      "1\n",
      "[1 2]\n",
      "[ 2 -1]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with step activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = np.array([1]), threshold = 0):\n",
    "        \"\"\"\n",
    "        Initialize weights and threshold based on input arguments. Note that no\n",
    "        type-checking is being performed here for simplicity.\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def activate(self,inputs):\n",
    "        \"\"\"\n",
    "        Takes in @param inputs, a list of numbers equal to length of weights.\n",
    "        @return the output of a threshold perceptron with given inputs based on\n",
    "        perceptron weights and threshold.\n",
    "        \"\"\" \n",
    "\n",
    "        # The strength with which the perceptron fires.\n",
    "        strength = np.dot(self.weights, inputs)\n",
    "\n",
    "        # TODO: return 0 or 1 based on the threshold\n",
    "        if strength <= self.threshold :\n",
    "            self.result = 0\n",
    "        else:\n",
    "            self.result = 1\n",
    "        return self.result\n",
    "\n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    Nothing should show up in the output if all the assertions pass.\n",
    "    \"\"\"\n",
    "    p1 = Perceptron(np.array([1, 2]), 0.)\n",
    "    assert p1.activate(np.array([ 1,-1])) == 0 # < threshold --> 0\n",
    "    assert p1.activate(np.array([-1, 1])) == 1 # > threshold --> 1\n",
    "    assert p1.activate(np.array([ 2,-1])) == 0 # on threshold --> 0\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SV)\n",
    "\n",
    "Multiple kernels can be specified.  Below, the \"linear\" kernel is selected which will provide linear modeling.  From previous videos this is the (t(x)y) component of the logistic algorithm.  Others are, 'ploy', 'rbf', 'sigmoid', 'precomputed' or a callable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X = [[0, 0], [1, 1]]\n",
    "y = [0, 1]\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Documentation is at http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict([[-0.8, -1]]))\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, Y, np.unique(Y))\n",
    "\n",
    "print(clf_pf.predict([[-0.8, -1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimal classifier code.\n",
    "\n",
    "Note, this uses concept of _Conditional Independence_ to minimize the calculations required.  This sais that 2 events **A** and **B** are _conditionally indiependent_ given a third event **Y** precicely if the occurence of **A** and **B** are _independent_ evenents in their _conditional probability distribution_ given **Y**.  \n",
    "\n",
    "Or, knowing the probabilty of **Y** relative to **A** and **B** adds no information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------\n",
    "\n",
    "#\n",
    "#   Bayes Optimal Classifier\n",
    "#\n",
    "#   In this quiz we will compute the optimal label for a second missing word in a row\n",
    "#   based on the possible words that could be in the first blank\n",
    "#\n",
    "#   Finish the procedurce, LaterWords(), below\n",
    "#\n",
    "#   You may want to import your code from the previous programming exercise!\n",
    "#\n",
    "\n",
    "sample_memo = '''\n",
    "Milt, we're gonna need to go ahead and move you downstairs into storage B. We have some new people coming in, and we need all the space we can get. So if you could just go ahead and pack up your stuff and move it down there, that would be terrific, OK?\n",
    "Oh, and remember: next Friday... is Hawaiian shirt day. So, you know, if you want to, go ahead and wear a Hawaiian shirt and jeans.\n",
    "Oh, oh, and I almost forgot. Ahh, I'm also gonna need you to go ahead and come in on Sunday, too...\n",
    "Hello Peter, whats happening? Ummm, I'm gonna need you to go ahead and come in tomorrow. So if you could be here around 9 that would be great, mmmk... oh oh! and I almost forgot ahh, I'm also gonna need you to go ahead and come in on Sunday too, kay. We ahh lost some people this week and ah, we sorta need to play catch up.\n",
    "'''\n",
    "\n",
    "corrupted_memo = '''\n",
    "Yeah, I'm gonna --- you to go ahead --- --- complain about this. Oh, and if you could --- --- and sit at the kids' table, that'd be --- \n",
    "'''\n",
    "\n",
    "data_list = sample_memo.strip().split()\n",
    "\n",
    "words_to_guess = [\"ahead\",\"could\"]\n",
    "\n",
    "def LaterWords(sample,word,distance):\n",
    "    '''@param sample: a sample of text to draw from\n",
    "    @param word: a word occuring before a corrupted sequence\n",
    "    @param distance: how many words later to estimate (i.e. 1 for the next word, 2 for the word after that)\n",
    "    @returns: a single word which is the most likely possibility\n",
    "    '''\n",
    "    \n",
    "    # TODO: Given a word, collect the relative probabilities of possible following words\n",
    "    # from @sample. You may want to import your code from the maximum likelihood exercise.\n",
    "    words = sample.split()\n",
    "    \n",
    "    #print \"The training set is:\", words\n",
    "    #print \"The word is:\", word, \".  What is the most likely word\", distance, \"words after it?\"\n",
    "    \n",
    "    res = {}\n",
    "    for i in range(len(words) - 1):\n",
    "        if word == words[i]:\n",
    "            n = i+1\n",
    "            res[words[n]] = res.get(words[n], 0) + 1\n",
    "                \n",
    "    s = sum(res.values()) * 1.0\n",
    "\n",
    "    for k in res:\n",
    "        res[k] = res[k] / s\n",
    "        \n",
    "    #print \"The first word(s) after\", word, \"is/are\", res\n",
    "    \n",
    "    # TODO: Repeat the above process--for each distance beyond 1, evaluate the words that\n",
    "    # might come after each word, and combine them weighting by relative probability\n",
    "    # into an estimate of what might appear next.\n",
    "    res_n = {}\n",
    "    for word1 in res:\n",
    "        res_i = {}\n",
    "        for i in range(len(words) - 1):\n",
    "            if word1 == words[i]:\n",
    "                n = i+distance-1\n",
    "                res_i[words[n]] = res_i.get(words[n], 0) + 1\n",
    "                \n",
    "        s = sum(res_i.values()) * 1.0\n",
    "        for i in res_i:\n",
    "            res_i[i] = res[word1] * res_i[i] / s\n",
    "            \n",
    "        res_n[word1] = res_i\n",
    "    \n",
    "    #for a in res_n:\n",
    "    #    print \"The first words after\", a, \"is/are:\", res_n[a]\n",
    "        \n",
    "    best = ''\n",
    "    prob = 0\n",
    "    for a in res_n:\n",
    "        for b in res_n[a]:\n",
    "            if prob < res_n[a][b]:\n",
    "                prob = res_n[a][b]\n",
    "                word = b\n",
    "                \n",
    "    return word\n",
    "    \n",
    "print LaterWords(sample_memo,\"ahead\",2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
